<!DOCTYPE html>
<html>

<head>
<meta charset="utf-8">
<title>Deep Learning for the Social Sciences</title>
<link rel="stylesheet" type="text/css" href="style.css">
</head>

<body>
<h1>Foundations of Deep Learning for the Social Sciences</h1>

  <h2 id="overview">Overview</h2>

    <img src="./pictures/neural_net.png" width="200" style="float:right">

    <p>Deep learning has revolutionized how complex processes are modeled in fields including <a href="https://github.com/CompVis/stable-diffusion">computer</a> <a href="https://en.wikipedia.org/wiki/DALL-E">vision</a>, <a href="https://en.wikipedia.org/wiki/GPT-3">natural language processing</a>, <a href="https://www.deepmind.com/research/highlighted-research/alphafold">computational biology</a>, <a href="https://www.nature.com/articles/s41586-021-03854-z">weather forecasting</a>, and <a href="https://www.deepmind.com/research/highlighted-research/alphago">game</a> <a href="https://www.nature.com/articles/nature14236">playing</a>. Despite these impressive breakthroughs, deep learning is rarely used to model complex behavioral processes in the social sciences.</p>

    <p>This two-day workshop will provide a broad, practical introduction to deep learning concepts and methods, with a particular focus on the benefits and drawbacks of applying these methods to analyze behavioral data. During the first day, you will learn how to build, fit, and evaluate deep learning models for predicting behavioral outcomes. We will start the day by introducing fundamental deep learning concepts in the familiar context of linear regression. We will finish the day with a hands-on overview of foundational deep learning models for analyzing both cross-sectional and longitudinal data.</p>

    <p>During the second day, you will learn about how traditional latent variable models used in the social sciences can be enhanced using deep learning. We will begin by investigating how deep learning software and optimization methods provide a flexible framework for estimating structural equation models with nonlinear constraints. We will conclude by exploring how to estimate highly flexible extensions of traditional structural equation and item response theory models in a computationally efficient manner using deep learning-based approximate inference methods.</p>

  <h2 id="learn">What You Will Learn</h2>

  <h2 id="instructor">Instructor</h2>

    <p>Christopher J. Urban, M.A.</br>
    Ph.D. Candidate in <a href="https://quantpsych.unc.edu/">Quantitative Psychology</a>, Univeristy of North Carolina at Chapel Hill</br>
    Homepage: <a href="https://cjurban.github.io/">https://cjurban.github.io/</a></br>
    E-mail: <SCRIPT LANGUAGE="JavaScript">user = 'cjurban';site = 'live.unc.edu';document.write('<a href=\"mailto:' + user + '@' + site + '\">');document.write(user + '@' + site + '</a>');</SCRIPT></p>

  <h2 id="prereqs">Prerequisites</h2>

    Necessary prerequisites:
    <ul>
      <li>Proficiency in <a href="https://en.wikipedia.org/wiki/Generalized_linear_model">generalized linear models</a>, particularly <a href="https://en.wikipedia.org/wiki/Linear_regression">linear regression</a> and <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a></li>
      <li>Proficiency in statistical programming (i.e., manipulating and analyzing data using a programming language like <a href="https://www.r-project.org/">R</a> or <a href="https://www.r-project.org/">Python</a>)</li>
      <li>Familiarity with with traditional latent variable modeling frameworks, particularly <a href="https://en.wikipedia.org/wiki/Structural_equation_modeling">structural equation modeling</a> and/or <a href="https://en.wikipedia.org/wiki/Item_response_theory">item response theory</a>
    </ul>
    Helpful (but not strictly necessary) prerequisites:
    <ul>
      <li>Familiarity with <a href="https://en.wikipedia.org/wiki/linear_algebra">Linear algrebra</a></li>
      <li>Familiarity with <a href="https://en.wikipedia.org/wiki/multivariable_calculus">Multivariable calculus</a></li>
      <li>Familiarity with basic machine learning concepts (e.g., <a href="https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)">hyperparameters</a>, <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">cross-validation</a>)
    </ul>

  <h2 id="computing">Computing Resources</h2>

  <h2 id="schedule">Tentative Schedule</h2>

    <table width=1000>
      <tr>
        <td width="3%"><b>&#35;</b></td>
        <td width="5%"><b>Date</b></td>
        <td width="15%"><b>Topic</b> </td>
        <td width="25%"><b>Learning Outcomes</b></td>
        <td width="25%"><b>Materials</b></td>
        <td width="25%"><b>Additional Resources</b></td>
      </tr>
      <tr>
        <td><b>1</b></td>
        <td>10/4</td>
        <td>Foundational Deep Learning Concepts
        </td>
        <td>
        </td>
        <td>
        </td>
        <td>
        </td>
      </tr>
      <tr>
        <td><b>2</b></td>
        <td>10/4</td>
        <td>Foundational Deep Learning Models
        </td>
        <td>
        </td>
        <td>
        </td>
        <td>
        </td>
      </tr>
      <tr>
        <td><b>3</b></td>
        <td>10/5</td>
        <td>Connections to Psychometrics
        </td>
        <td>
        </td>
        <td>
        </td>
        <td>
          <u>Deep Learning and Structural Equation Modeling</u></br>
          <ul>
            <li>van Kesteren, E.-J., & Oberski, D. L. (2022). <a href="https://www.tandfonline.com/doi/full/10.1080/10705511.2021.1971527">Flexible extensions to structural equation models using computation graphs.</a></li>
          </ul>
          <u>Deep Learning and Item Response Theory</u></br>
          <ul>
            <li>Curi, M., Converse, G. A., Hajewski, J., & Oliveira, S. (2019). <a href="https://ieeexplore.ieee.org/document/8852333">Interpretable variational autoencoders for cognitive models.</a></li>
            <li>Wu, M., ..., & Goodman, N. (2020). <a href="https://arxiv.org/abs/2002.00276">Variational item response theory: Fast, accurate, expressive.</a></li>
            <li>Urban, C. J., & Bauer, D. J. (2021). <a href="https://link.springer.com/article/10.1007/s11336-021-09748-3">A deep learning algorithm for high-dimensional exploratory item factor analysis.</a></li>
          </ul>
        </td>
      </tr>
    </table>

</body>
</html>
